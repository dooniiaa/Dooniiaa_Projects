{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"z4T_oJvcmYkW","executionInfo":{"status":"error","timestamp":1726751893737,"user_tz":-60,"elapsed":329,"user":{"displayName":"Dounia KAMEL","userId":"03559397845352283036"}},"outputId":"78861fe5-a50d-4930-d1b5-835cc210ff99","colab":{"base_uri":"https://localhost:8080/","height":383}},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'face_recognition'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-9ed71231e664>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m  \u001b[0;31m#pour le traitement d'images et la vision par ordinateur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m   \u001b[0;31m#une bibliothèque spécialisée dans la reconnaissance faciale.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m   \u001b[0;31m# manipuler les fichiers et les répertoires\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m  \u001b[0;31m# rechercher des fichiers et des répertoires en utilisant des motifs de recherche\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m   \u001b[0;31m# pour le calcul numérique en Python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'face_recognition'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import cv2  #pour le traitement d'images et la vision par ordinateur\n","import face_recognition   #une bibliothèque spécialisée dans la reconnaissance faciale.\n","import os   # manipuler les fichiers et les répertoires\n","import glob  # rechercher des fichiers et des répertoires en utilisant des motifs de recherche\n","import numpy as np   # pour le calcul numérique en Python\n","import matplotlib.pyplot as plt  #bibliothèque de visualisation en 2D"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"EI3SUtlPmYkb","executionInfo":{"status":"ok","timestamp":1726751894062,"user_tz":-60,"elapsed":8,"user":{"displayName":"Dounia KAMEL","userId":"03559397845352283036"}}},"outputs":[],"source":["\n","class Facerec: # créée une classe pour encapsuler les fonctionnalités liées à la reconnaissance faciale.\n","    def __init__(self):\n","        self.known_faces_encodings = []   #pour stocker les encodages des visages connus.\n","        self.known_faces_names = []   #pour stocker les noms des visages connus.\n","        self.frame_resizing = 0.25   # coefficient de redimensionnement des images de trame\n","\n","    def apply_filters(self, img):\n","        # Convert to grayscale for Laplacian filter\n","        rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        gray_img = cv2.cvtColor(rgb_img, cv2.COLOR_BGR2GRAY)\n","        hist = cv2.calcHist([gray_img], [0], None, [256], [0,256])\n","        #Normalisation de l'image en niveaux de gris\n","        Imin, Imax = np.min(gray_img), np.max(gray_img)\n","        img_normalized = (255 / (Imax - Imin)) * (gray_img - Imin)\n","        #Sharpening using the provided kernel\n","        kernel = np.array(([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]), dtype=np.float32)\n","        img_sharpened = cv2.filter2D(img_normalized, -1, kernel) #filtre de renforcement des contours en utilisant une convolution avec un noyau prédéfini\n","        img_sharpened = np.clip(img_sharpened, 0, 255) #np.clip est utilisée pour s'assurer que les valeurs restent dans la plage 0-255.\n","        gauss_blur = cv2.GaussianBlur(img_sharpened,(3,3),1) #Un filtre de flou gaussien est appliqué à l'image (reduire le bruit)\n","        #Filtres de Sobel (détection des contours)\n","        noy_sbx = np.array([[-1,0,1],[-2,0,2],[-1,0,1]])\n","        noy_sby = np.array([[-1,-2,-1],[0,0,0],[1,2,1]])\n","        horizs = cv2.filter2D(gauss_blur,-1,noy_sby)\n","        vertics = cv2.filter2D(gauss_blur,-1,noy_sbx)\n","        #Calcul du module du gradient Sobel\n","        module_sobel = np.sqrt(np.square(vertics.astype(np.float32)) + np.square(horizs.astype(np.float32)))\n","        mod_sb = np.uint8(module_sobel)\n","        #Amélioration de l'image d'origine avec le gradient( en ajoutant 50% du module du gradient Sobel.)\n","        enhanced_image = cv2.addWeighted(gray_img, 1, mod_sb, 0.5, 0) # Combinaison\n","\n","        return img_normalized,img_sharpened, mod_sb ,enhanced_image\n","\n","    def display_images(self, normalized, sharpened, edge_detection):\n","      # Display original and preprocessed images\n","        plt.figure(figsize=(10, 8))\n","\n","\n","        plt.subplot(2, 4, 1), plt.imshow(normalized, cmap='gray')\n","        plt.title('Normalized'), plt.axis('off')\n","\n","        plt.subplot(2, 4, 2), plt.imshow(sharpened, cmap='gray')\n","        plt.title('Sharpened'), plt.axis('off')\n","\n","        plt.subplot(2, 4, 3), plt.imshow(edge_detection, cmap='gray')\n","        plt.title('edge detection'), plt.axis('off')\n","\n","        plt.show()\n","\n","    def process_images_in_folder(self, folder_path):\n","        # Iterate through all images in the folder\n","        for filename in os.listdir(folder_path):  #os.listdir(folder_path) pour obtenir la liste des fichiers dans le dossier.\n","            if filename.endswith(('.png', '.jpg', '.jpeg','.JPG')): #vérification s'il a une extension\n","                # Read the image\n","                img_path = os.path.join(folder_path, filename)\n","                img = cv2.imread(img_path)\n","\n","                # Apply filters\n","                img_normalized, img_sharpened,mod_sb ,enhanced_image  = self.apply_filters(img)\n","\n","                # Display images\n","                self.display_images(img_normalized, img_sharpened, mod_sb)\n","\n","    def load_encoding_images(self, images_path):  # Méthode pour charger les images et leurs encodages.\n","        images_path = glob.glob(os.path.join(images_path, \"*.*\")) #Utilise glob.glob pour obtenir une liste de chemins d'images dans le répertoire spécifié (images_path).\n","        print(\"{} encoding images found.\".format(len(images_path))) #Affiche le nombre d'images trouvées dans le répertoire\n","\n","        for img_path in images_path:\n","            img = cv2.imread(img_path)\n","\n","            # Appliquer les filtres à chaque image.\n","            img_normalized, img_sharpened,mod_sb ,enhanced_image  = self.apply_filters(img)\n","            rgb_img = cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2RGB)#Convertit l'image en BGR\n","\n","            basename = os.path.basename(img_path)\n","            (filename, ext) = os.path.splitext(basename)#pour obtenir le nom du fichier et son extension à partir du chemin d'accès de l'image.\n","\n","            # Get encoding\n","            face_encodings = face_recognition.face_encodings(rgb_img)#pour obtenir les encodages des visages dans l'image.\n","\n","            if face_encodings:\n","                #Stocker le nom du fichier et les encodages de visage dans les listes\n","                self.known_faces_encodings.extend(face_encodings)\n","                self.known_faces_names.extend([filename] * len(face_encodings))\n","                #Duplique le nom du fichier pour chaque visage détecté.\n","            else:\n","                # Handle the case when no face encodings are found\n","                print(\"No face encodings found for image:\", img_path)\n","\n","        print(\"Encoding images loaded\")\n","\n","    def detect_known_faces(self, frame):\n","        small_frame = cv2.resize(frame, (0, 0), fx=self.frame_resizing, fy=self.frame_resizing)   #Redimensionne la trame d'entrée (frame) en utilisant la fonction cv2.resize\n","                                                                                                  # fx et fy déterminent le facteur de redimensionnement en largeur et en hauteur respectivement.\n","\n","        # Convert the image from BGR color to RGB color\n","        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n","        face_locations = face_recognition.face_locations(rgb_small_frame)  #détecter les emplacements des visages dans la trame\n","        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)   #extraire les encodages faciaux des visages détectés\n","                                                                                             #Ces encodages sont utilisés pour comparer les visages détectés avec les visages connus stockés précédemment\n","\n","        face_names = []\n","        for face_encoding in face_encodings:\n","            # See if the face is a match for the known face\n","            matches = face_recognition.compare_faces(self.known_faces_encodings, face_encoding)\n","            name = \"Unknown\"\n","\n","            #Calcule les distances entre l'encodage facial actuel et les encodages faciaux des visages connus.\n","            face_distances = face_recognition.face_distance(self.known_faces_encodings, face_encoding)\n","            best_match_index = np.argmin(face_distances)  # Trouve l'index du visage connu avec la plus petite distance par rapport au visage actuellement détecté.\n","            if matches[best_match_index]:\n","                name = self.known_faces_names[best_match_index]  #met à jour le nom du visage détecté avec le nom du visage connu correspondant.\n","            face_names.append(name)   #Ajoute le nom du visage à la liste face_names\n","\n","        # Convert to numpy array to adjust coordinates with frame resizing quickly\n","        face_locations = np.array(face_locations)\n","        face_locations = face_locations / self.frame_resizing  #Ajuste les coordonnées des emplacements des visages en fonction du facteur de redimensionnement\n","        return face_locations.astype(int), face_names  # Retourne un tuple contenant les emplacements des visages en tant que tableau d'entiers et les noms des visages détectés.\n","\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"KZpFyhHAbiPE","executionInfo":{"status":"error","timestamp":1726751894062,"user_tz":-60,"elapsed":7,"user":{"displayName":"Dounia KAMEL","userId":"03559397845352283036"}},"outputId":"210e0d15-2df9-4e0b-c9d5-a5f2c6a517e5","colab":{"base_uri":"https://localhost:8080/","height":297}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'os' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-35d4b272e238>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfacerec_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFacerec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfolder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"images/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfacerec_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_images_in_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-8fd6a47df560>\u001b[0m in \u001b[0;36mprocess_images_in_folder\u001b[0;34m(self, folder_path)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_images_in_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Iterate through all images in the folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#os.listdir(folder_path) pour obtenir la liste des fichiers dans le dossier.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.jpeg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'.JPG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#vérification s'il a une extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;31m# Read the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"]}],"source":["#Display result images\n","facerec_instance = Facerec()\n","folder_path = \"images/\"\n","facerec_instance.process_images_in_folder(folder_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p3EGPyojmYkc","executionInfo":{"status":"aborted","timestamp":1726751894063,"user_tz":-60,"elapsed":6,"user":{"displayName":"Dounia KAMEL","userId":"03559397845352283036"}}},"outputs":[],"source":["\n","sfr = Facerec()\n","sfr.load_encoding_images(\"images/\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pb9kKcUymYke","executionInfo":{"status":"aborted","timestamp":1726751894063,"user_tz":-60,"elapsed":6,"user":{"displayName":"Dounia KAMEL","userId":"03559397845352283036"}}},"outputs":[],"source":["cap = cv2.VideoCapture(0) #Initialise la capture vidéo en utilisant la webcam\n","while True: #boucle pour capturer des images en continu.\n","    #Lit une image à partir de la webcam\n","    ret, frame = cap.read()  #La variable frame contient l'image capturée.\n","    #Detection des visages\n","    face_locations,face_names =sfr.detect_known_faces(frame) #pour détecter les visages connus dans l'image\n","    for face_loc,name in zip(face_locations,face_names):\n","      #Boucle à travers chaque paire de coordonnées de visage et nom associé.\n","        y1, x2, y2, x1 = face_loc[0] , face_loc[1], face_loc[2], face_loc[3] # pour obtenir les positions des coins du rectangle délimitant le visage.\n","        cv2.putText(frame,name,(x1,y1-10),cv2.FONT_HERSHEY_DUPLEX,1,(0,0,200),2) #Ajoute le nom du visage au cadre à une position spécifique au-dessus du visage.\n","        cv2.rectangle(frame,(x1,y1),(x2, y2),(0,0,200),4) #pour Dessiner un rectangle autour du visage sur l'image capturée.\n","    cv2.imshow(\"Frame\",frame)\n","    key = cv2.waitKey(1)\n","    if key == 27:  #Si la touche pressée est la touche Échap (code 27), cela casse la boucle (break), mettant fin à la capture vidéo.\n","        break\n","\n","cap.release()  #Libère la ressource de capture vidéo.\n","cv2.destroyAllWindows() #Ferme toutes les fenêtres d'affichage OpenCV."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":0}